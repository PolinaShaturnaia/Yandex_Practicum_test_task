# Yandex_Practicum_test_task

В этом тестовом задании будем классифицировать посты из твиттера.

В файле train.csv мы найдем 30 000 постов, каждый из которых сопоставлен с одним из 13 классов эмоций.
В test.csv находятся еще 10 000 постов, для которых эмоцию нужно предсказать.

Результат предсказания положим в файл test_predictions.csv.
Метрика качества - accuracy.

**Для работы с данным заданием мы применяли библиотеки:**
torch: библиотека PyTorch применяется в задачах обработки естественного текста и компьютерного зрения
transformers: библиотека PyTorch для работы с моделями типа BERT
tqdm: библиотека, которая наглядно показывает индикатор прогресса. В Jupyter применим функцию notebook() из этой библиотеки в момент создания эмбеддингов
pymystem3: библиотека предоставляет программный интерфейс к анализатору для языка программирования Python
Mystem: морфологический анализатор
re: встроенный модуль для работы с регулярными выражениями
nltk: пакет библиотек и программ для символьной и статистической обработки естественного языка
TfidfVectorizer: счётчик величин TF-IDF
train_test_split: функция для разделения датафрейма перед обучением
GridSearchCV: инструмент для автоматического подбора параметров для моделей машинного обучения

**Модели машинного обучения:**
DecisionTreeClassifier
RandomForestClassifier
LogisticRegression

**Мы применили 2 метода подготовки текстов к обучению.**
С помощью BERT мы создали векторные представления постов.
С помощью TF-IDF мы провели оценку важности слов.

После подготовки постов мы обучили 3 модели машинного обучения: Классификатор дерева решений, Случайный лес и Логистическая регрессия.
С помощью метрики **accuracy** мы выбрали наилучшую модель машинного обучения и с помощью нее получили целевые признаки - эмоцию - для тестового датасета.

Результат предсказания мы сохранили в файл **test_predictions.csv**.

**Дополнительно**

Для применения метода BERT была использована предобученная многоязычная модель BERT-base: http://files.deeppavlov.ai/deeppavlov_data/bert/multi_cased_L-12_H-768_A-12_pt.tar.gz

data_features_train и data_features_test, полученные путем создания эмбеддингов можно посмотреть:
data_features_train: https://drive.google.com/file/d/1Dd60PY35epstIC3g_str27SPjqbWDx8O/view?usp=sharing
data_features_test: https://drive.google.com/file/d/1qKUGqiZ_9hBctSLn1bJ-xA2MM1YPUGVE/view?usp=sharing
